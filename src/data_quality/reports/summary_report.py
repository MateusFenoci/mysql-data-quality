"""Summary report generator for data quality results."""

from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from ..validators.base import ValidationResult
from .base import ReportGenerator


class SummaryReportGenerator(ReportGenerator):
    """Generates concise text summary reports from validation results."""

    def generate_report(
        self,
        results: List[ValidationResult],
        table_name: str,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """Generate summary text report from validation results."""
        summary = self._analyze_results(results)

        # Create summary content
        content = self._create_summary_content(results, table_name, summary, metadata)

        # Generate filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"data_quality_summary_{table_name}_{timestamp}.txt"
        output_path = self.output_dir / filename

        # Write summary report
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)

        return output_path

    def _create_summary_content(
        self,
        results: List[ValidationResult],
        table_name: str,
        summary: Dict[str, Any],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Create summary report content."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        content = f"""
        ðŸ” DATA QUALITY SUMMARY REPORT
        {'=' * 50}

        Table: {table_name}
        Generated: {timestamp}
        {f'Metadata: {metadata}' if metadata else ''}

        ðŸ“Š OVERALL SUMMARY
        {'-' * 20}
        Total Checks:    {summary['total_checks']}
        Passed:          {summary['passed_checks']} âœ…
        Failed:          {summary['failed_checks']} âŒ
        Success Rate:    {summary['success_rate']:.1f}%

        Quality Score: {self._get_quality_score(summary['success_rate'])}

        """

        # Add validator breakdown
        if summary["validator_breakdown"]:
            content += "ðŸ”§ VALIDATOR BREAKDOWN\n"
            content += "-" * 25 + "\n"

            for validator_type, counts in summary["validator_breakdown"].items():
                success_rate = (
                    (counts["passed"] / counts["total"]) * 100
                    if counts["total"] > 0
                    else 100
                )
                status = self._get_status_indicator(success_rate)

                content += f"{validator_type.title():12} {status} "
                content += f"{counts['passed']:3}/{counts['total']:<3} ({success_rate:5.1f}%)\n"

            content += "\n"

        # Add severity breakdown
        if summary["severity_breakdown"]:
            content += "âš–ï¸ SEVERITY BREAKDOWN\n"
            content += "-" * 21 + "\n"

            severity_order = ["CRITICAL", "ERROR", "WARNING", "INFO"]
            for severity in severity_order:
                if severity in summary["severity_breakdown"]:
                    counts = summary["severity_breakdown"][severity]
                    icon = self._get_severity_icon(severity)
                    content += f"{icon} {severity:8} {counts['failed']:3} failed / {counts['total']:3} total\n"

            content += "\n"

        # Add top issues
        failed_results = [r for r in results if not r.passed]
        if failed_results:
            content += "ðŸš¨ TOP ISSUES\n"
            content += "-" * 12 + "\n"

            # Sort by severity and affected rows
            severity_priority = {"CRITICAL": 0, "ERROR": 1, "WARNING": 2, "INFO": 3}
            sorted_results = sorted(
                failed_results[:10],  # Top 10 issues
                key=lambda r: (
                    severity_priority.get(r.severity.value, 4),
                    -r.affected_rows,
                ),
            )

            for i, result in enumerate(sorted_results, 1):
                severity_icon = self._get_severity_icon(result.severity.value)
                column_info = f"[{result.column_name}] " if result.column_name else ""

                content += f"{i:2}. {severity_icon} {column_info}{result.rule_name}\n"
                content += f"    {result.message}\n"

                if result.affected_rows > 0:
                    content += f"    ðŸ“ˆ {result.affected_rows:,} / {result.total_rows:,} rows affected ({result.pass_rate:.1f}% pass rate)\n"

                content += "\n"

        # Add recommendations
        content += "ðŸ’¡ RECOMMENDATIONS\n"
        content += "-" * 18 + "\n"
        content += self._generate_recommendations(summary, failed_results)

        content += "\n" + "=" * 50 + "\n"
        content += "Report generated by Data Quality Tool\n"

        return content

    def _get_quality_score(self, success_rate: float) -> str:
        """Get quality score description based on success rate."""
        if success_rate >= 95:
            return "ðŸŸ¢ EXCELLENT"
        elif success_rate >= 85:
            return "ðŸŸ¡ GOOD"
        elif success_rate >= 70:
            return "ðŸŸ  FAIR"
        elif success_rate >= 50:
            return "ðŸ”´ POOR"
        else:
            return "ðŸ’€ CRITICAL"

    def _get_status_indicator(self, success_rate: float) -> str:
        """Get status indicator for success rate."""
        if success_rate >= 90:
            return "âœ…"
        elif success_rate >= 70:
            return "âš ï¸ "
        else:
            return "âŒ"

    def _get_severity_icon(self, severity: str) -> str:
        """Get icon for severity level."""
        icons = {"CRITICAL": "ðŸš¨", "ERROR": "âŒ", "WARNING": "âš ï¸ ", "INFO": "ðŸ’¡"}
        return icons.get(severity, "â“")

    def _generate_recommendations(
        self, summary: Dict[str, Any], failed_results: List[ValidationResult]
    ) -> str:
        """Generate recommendations based on validation results."""
        recommendations = []

        # Overall success rate recommendations
        if summary["success_rate"] < 70:
            recommendations.append(
                "â€¢ Focus on critical issues first - success rate below 70%"
            )

        # Validator-specific recommendations
        for validator_type, counts in summary["validator_breakdown"].items():
            success_rate = (
                (counts["passed"] / counts["total"]) * 100
                if counts["total"] > 0
                else 100
            )

            if success_rate < 80:
                if validator_type == "completeness":
                    recommendations.append(
                        "â€¢ Address data completeness issues - consider data collection improvements"
                    )
                elif validator_type == "duplicates":
                    recommendations.append(
                        "â€¢ Review duplicate data - implement deduplication processes"
                    )
                elif validator_type == "patterns":
                    recommendations.append(
                        "â€¢ Fix data format issues - standardize input validation"
                    )
                elif validator_type == "integrity":
                    recommendations.append(
                        "â€¢ Resolve referential integrity issues - check foreign key constraints"
                    )

        # High-impact issues
        high_impact_issues = [r for r in failed_results if r.affected_rows > 100]
        if high_impact_issues:
            recommendations.append(
                f"â€¢ Prioritize {len(high_impact_issues)} high-impact issues affecting >100 rows each"
            )

        # Critical/Error severity recommendations
        critical_errors = [
            r for r in failed_results if r.severity.value in ["CRITICAL", "ERROR"]
        ]
        if critical_errors:
            recommendations.append(
                f"â€¢ Address {len(critical_errors)} critical/error issues immediately"
            )

        # Default recommendation if no specific issues found
        if not recommendations:
            if summary["success_rate"] >= 95:
                recommendations.append(
                    "â€¢ Data quality is excellent - maintain current standards"
                )
            else:
                recommendations.append("â€¢ Continue monitoring data quality trends")
                recommendations.append(
                    "â€¢ Consider implementing automated data quality checks"
                )

        return (
            "\n".join(recommendations)
            if recommendations
            else "No specific recommendations at this time."
        )
